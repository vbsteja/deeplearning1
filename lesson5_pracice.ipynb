{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: GeForce 940MX (0000:03:00.0)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_idx = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88584"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = 'data/imdb/models/'\n",
    "%mkdir -p $model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_arr = sorted(data_idx,key=data_idx.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx2word = {k:v for v,k in data_idx.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = file(\"data/imdb/imdb_full.pkl\",\"rb\")\n",
    "(x_train, labels_train), (x_test, labels_test) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bromwell\n",
      "programs\n",
      "teachers\n",
      "teaching\n",
      "profession\n",
      "bromwell\n",
      "high's\n",
      "teachers\n",
      "scramble\n",
      "financially\n",
      "insightful\n",
      "teachers'\n",
      "pomp\n",
      "pettiness\n",
      "schools\n",
      "recalled\n",
      "sack\n",
      "teachers\n",
      "bromwell\n",
      "bromwell\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bergman'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_rare = [i for i in x_train[0] if i > 5000]\n",
    "for i in list_of_rare:\n",
    "    print(idx2word[i])\n",
    "    \n",
    "idx2word[4999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'23022, 309, 6, 3, 1069, 209, 9, 2175, 30, 1, 169, 55, 14, 46, 82, 5869, 41, 393, 110, 138, 14, 5359, 58, 4477, 150, 8, 1, 5032, 5948, 482, 69, 5, 261, 12, 23022, 73935, 2003, 6, 73, 2436, 5, 632, 71, 6, 5359, 1, 25279, 5, 2004, 10471, 1, 5941, 1534, 34, 67, 64, 205, 140, 65, 1232, 63526, 21145, 1, 49265, 4, 1, 223, 901, 29, 3024, 69, 4, 1, 5863, 10, 694, 2, 65, 1534, 51, 10, 216, 1, 387, 8, 60, 3, 1472, 3724, 802, 5, 3521, 177, 1, 393, 10, 1238, 14030, 30, 309, 3, 353, 344, 2989, 143, 130, 5, 7804, 28, 4, 126, 5359, 1472, 2375, 5, 23022, 309, 10, 532, 12, 108, 1470, 4, 58, 556, 101, 12, 23022, 309, 6, 227, 4187, 48, 3, 2237, 12, 9, 215'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(map(str,x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88584"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"bromwell high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my 35 years in the teaching profession lead me to believe that bromwell high's satire is much closer to reality than is teachers the scramble to survive financially the insightful students who can see right through their pathetic teachers' pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled at high a classic line inspector i'm here to sack one of your teachers student welcome to bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it isn't\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(idx2word[o]for o in x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"homelessness or houselessness as george carlin stated has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school work or vote for the matter most people think of the homeless as just a lost cause while worrying about things such as racism the war on iraq pressuring kids to succeed technology the elections inflation or worrying if they'll be next to end up on the streets br br but what if you were given a bet to live on the streets for a month without the luxuries you once had from a home the entertainment sets a bathroom pictures on the wall a computer and everything you once treasure to see what it's like to be homeless that is goddard bolt's lesson br br mel brooks who directs who stars as bolt plays a rich man who has everything in the world until deciding to make a bet with a sissy rival jeffery tambor to see if he can live in the streets for thirty days without the luxuries if bolt succeeds he can do what he wants with a future project of making more buildings the bet's on where bolt is thrown on the street with a bracelet on his leg to monitor his every move where he can't step off the sidewalk he's given the nickname pepto by a vagrant after it's written on his forehead where bolt meets other characters including a woman by the name of molly lesley ann warren an ex dancer who got divorce before losing her home and her pals sailor howard morris and fumes teddy wilson who are already used to the streets they're survivors bolt isn't he's not used to reaching mutual agreements like he once did when being rich where it's fight or flight kill or be killed br br while the love connection between molly and bolt wasn't necessary to plot i found life stinks to be one of mel brooks' observant films where prior to being a comedy it shows a tender side compared to his slapstick work such as blazing saddles young frankenstein or spaceballs for the matter to show what it's like having something valuable before losing it the next day or on the other hand making a stupid bet like all rich people do when they don't know what to do with their money maybe they should give it to the homeless instead of using it like monopoly money br br or maybe this film will inspire you to help others\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(idx2word[o] for o in x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "trn = np.array([[i if i<vocab_size-1 else vocab_size-1 for i in s]for s in x_train])\n",
    "tst = np.array([[i if i<vocab_size-1 else vocab_size-1 for i in s]for s in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lens = map(len,trn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2493, 10, 237.71364)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(lens),min(lens),np.mean(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = 500\n",
    "trn_seq = sequence.pad_sequences(trn,maxlen=seq_len,value=0.0)\n",
    "tst_seq = sequence.pad_sequences(tst,maxlen=seq_len,value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trn_seq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9ccce396eeb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrn_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trn_seq' is not defined"
     ]
    }
   ],
   "source": [
    "trn_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4999,\n",
       " 309,\n",
       " 6,\n",
       " 3,\n",
       " 1069,\n",
       " 209,\n",
       " 9,\n",
       " 2175,\n",
       " 30,\n",
       " 1,\n",
       " 169,\n",
       " 55,\n",
       " 14,\n",
       " 46,\n",
       " 82,\n",
       " 4999,\n",
       " 41,\n",
       " 393,\n",
       " 110,\n",
       " 138,\n",
       " 14,\n",
       " 4999,\n",
       " 58,\n",
       " 4477,\n",
       " 150,\n",
       " 8,\n",
       " 1,\n",
       " 4999,\n",
       " 4999,\n",
       " 482,\n",
       " 69,\n",
       " 5,\n",
       " 261,\n",
       " 12,\n",
       " 4999,\n",
       " 4999,\n",
       " 2003,\n",
       " 6,\n",
       " 73,\n",
       " 2436,\n",
       " 5,\n",
       " 632,\n",
       " 71,\n",
       " 6,\n",
       " 4999,\n",
       " 1,\n",
       " 4999,\n",
       " 5,\n",
       " 2004,\n",
       " 4999,\n",
       " 1,\n",
       " 4999,\n",
       " 1534,\n",
       " 34,\n",
       " 67,\n",
       " 64,\n",
       " 205,\n",
       " 140,\n",
       " 65,\n",
       " 1232,\n",
       " 4999,\n",
       " 4999,\n",
       " 1,\n",
       " 4999,\n",
       " 4,\n",
       " 1,\n",
       " 223,\n",
       " 901,\n",
       " 29,\n",
       " 3024,\n",
       " 69,\n",
       " 4,\n",
       " 1,\n",
       " 4999,\n",
       " 10,\n",
       " 694,\n",
       " 2,\n",
       " 65,\n",
       " 1534,\n",
       " 51,\n",
       " 10,\n",
       " 216,\n",
       " 1,\n",
       " 387,\n",
       " 8,\n",
       " 60,\n",
       " 3,\n",
       " 1472,\n",
       " 3724,\n",
       " 802,\n",
       " 5,\n",
       " 3521,\n",
       " 177,\n",
       " 1,\n",
       " 393,\n",
       " 10,\n",
       " 1238,\n",
       " 4999,\n",
       " 30,\n",
       " 309,\n",
       " 3,\n",
       " 353,\n",
       " 344,\n",
       " 2989,\n",
       " 143,\n",
       " 130,\n",
       " 5,\n",
       " 4999,\n",
       " 28,\n",
       " 4,\n",
       " 126,\n",
       " 4999,\n",
       " 1472,\n",
       " 2375,\n",
       " 5,\n",
       " 4999,\n",
       " 309,\n",
       " 10,\n",
       " 532,\n",
       " 12,\n",
       " 108,\n",
       " 1470,\n",
       " 4,\n",
       " 58,\n",
       " 556,\n",
       " 101,\n",
       " 12,\n",
       " 4999,\n",
       " 309,\n",
       " 6,\n",
       " 227,\n",
       " 4187,\n",
       " 48,\n",
       " 3,\n",
       " 2237,\n",
       " 12,\n",
       " 9,\n",
       " 215]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0, 4999,  309,    6,    3, 1069,  209,    9, 2175,   30,    1,  169,   55,   14,\n",
       "         46,   82, 4999,   41,  393,  110,  138,   14, 4999,   58, 4477,  150,    8,    1, 4999,\n",
       "       4999,  482,   69,    5,  261,   12, 4999, 4999, 2003,    6,   73, 2436,    5,  632,   71,\n",
       "          6, 4999,    1, 4999,    5, 2004, 4999,    1, 4999, 1534,   34,   67,   64,  205,  140,\n",
       "         65, 1232, 4999, 4999,    1, 4999,    4,    1,  223,  901,   29, 3024,   69,    4,    1,\n",
       "       4999,   10,  694,    2,   65, 1534,   51,   10,  216,    1,  387,    8,   60,    3, 1472,\n",
       "       3724,  802,    5, 3521,  177,    1,  393,   10, 1238, 4999,   30,  309,    3,  353,  344,\n",
       "       2989,  143,  130,    5, 4999,   28,    4,  126, 4999, 1472, 2375,    5, 4999,  309,   10,\n",
       "        532,   12,  108, 1470,    4,   58,  556,  101,   12, 4999,  309,    6,  227, 4187,   48,\n",
       "          3, 2237,   12,    9,  215], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_seq[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Neural Network with one hidden unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([Embedding(vocab_size,32,input_length=seq_len),\n",
    "                    Flatten(),\n",
    "                    Dense(100,activation=\"relu\"),\n",
    "                    Dropout(0.5),\n",
    "                    Dense(1,activation=\"sigmoid\")\n",
    "                   ]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 10s - loss: 0.5315 - acc: 0.6949 - val_loss: 0.2949 - val_acc: 0.8749\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 10s - loss: 0.2109 - acc: 0.9194 - val_loss: 0.2870 - val_acc: 0.8817\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 12s - loss: 0.0874 - acc: 0.9733 - val_loss: 0.3526 - val_acc: 0.8727\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 12s - loss: 0.0272 - acc: 0.9947 - val_loss: 0.4078 - val_acc: 0.8700\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 12s - loss: 0.0078 - acc: 0.9993 - val_loss: 0.4809 - val_acc: 0.8706\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 12s - loss: 0.0033 - acc: 0.9999 - val_loss: 0.5159 - val_acc: 0.8721\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 12s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5483 - val_acc: 0.8718\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 12s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5769 - val_acc: 0.8713\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 12s - loss: 7.7039e-04 - acc: 1.0000 - val_loss: 0.5950 - val_acc: 0.8720\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 12s - loss: 5.5269e-04 - acc: 1.0000 - val_loss: 0.6123 - val_acc: 0.8708\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 12s - loss: 4.3721e-04 - acc: 1.0000 - val_loss: 0.6311 - val_acc: 0.8712\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 12s - loss: 3.4048e-04 - acc: 1.0000 - val_loss: 0.6465 - val_acc: 0.8711\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 12s - loss: 2.7519e-04 - acc: 1.0000 - val_loss: 0.6610 - val_acc: 0.8708\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 13s - loss: 2.4071e-04 - acc: 1.0000 - val_loss: 0.6743 - val_acc: 0.8710\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 12s - loss: 1.9535e-04 - acc: 1.0000 - val_loss: 0.6854 - val_acc: 0.8712\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 12s - loss: 1.7197e-04 - acc: 1.0000 - val_loss: 0.6986 - val_acc: 0.8712\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 12s - loss: 1.2448e-04 - acc: 1.0000 - val_loss: 0.7090 - val_acc: 0.8709\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 13s - loss: 1.0940e-04 - acc: 1.0000 - val_loss: 0.7207 - val_acc: 0.8716\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 12s - loss: 9.7141e-05 - acc: 1.0000 - val_loss: 0.7294 - val_acc: 0.8716\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 12s - loss: 8.4835e-05 - acc: 1.0000 - val_loss: 0.7416 - val_acc: 0.8717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efe221cfed0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn_seq,labels_train,validation_data=(tst_seq,labels_test),batch_size=128,nb_epoch=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv layer with maxpooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model = Sequential([\n",
    "    Embedding(vocab_size,32,input_length=seq_len,dropout=0.2),\n",
    "    Dropout(0.2),\n",
    "    Convolution1D(nb_filter=64,filter_length=5,border_mode='same',activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(output_dim=1,activation=\"sigmoid\")\n",
    "])\n",
    "conv_model.compile(optimizer=Adam(),loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 228s - loss: 0.4062 - acc: 0.8227 - val_loss: 0.3017 - val_acc: 0.8734\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 214s - loss: 0.2991 - acc: 0.8790 - val_loss: 0.2731 - val_acc: 0.8889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efe23682050>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.fit(trn_seq,labels_train,batch_size=256,nb_epoch=2,validation_data=(tst_seq,labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model.save_weights(model_path+\"con\n",
    "                        v1.h5\");\n",
    "conv_model.load_weights(model_path+\"conv1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using pretrained word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_glove_dataset(dataset):\n",
    "    \"\"\"Download the requested glove dataset from files.fast.ai\n",
    "    and return a location that can be passed to load_vectors.\n",
    "    \"\"\"\n",
    "    # see wordvectors.ipynb for info on how these files were\n",
    "    # generated from the original glove data.\n",
    "    md5sums = {'6B.50d': '8e1557d1228decbda7db6dfd81cd9909',\n",
    "               '6B.100d': 'c92dbbeacde2b0384a43014885a60b2c',\n",
    "               '6B.200d': 'af271b46c04b0b2e41a84d8cd806178d',\n",
    "               '6B.300d': '30290210376887dcc6d0a5a6374d8255'}\n",
    "    glove_path = os.path.abspath('data/glove/results')\n",
    "    %mkdir -p $glove_path\n",
    "    return get_file(dataset,\n",
    "                    'http://files.fast.ai/models/glove/' + dataset + '.tgz',\n",
    "                    cache_subdir=glove_path,\n",
    "                    md5_hash=md5sums.get(dataset, None),\n",
    "                    untar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_vectors(loc):\n",
    "    return (load_array(loc+'.dat'),\n",
    "        pickle.load(open(loc+'_words.pkl','rb')),\n",
    "        pickle.load(open(loc+'_idx.pkl','rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untaring file...\n"
     ]
    }
   ],
   "source": [
    "vecs,words,idx = load_vectors(get_glove_dataset('6B.50d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_emb():\n",
    "    n_fact = vecs.shape[1]\n",
    "    emb = np.zeros((vocab_size, n_fact))\n",
    "\n",
    "    for i in range(1,len(emb)):\n",
    "        word = idx2word[i]\n",
    "        if word and re.match(r\"^[a-zA-Z0-9\\-]*$\", word):\n",
    "            src_idx = idx[word]\n",
    "            emb[i] = vecs[src_idx]\n",
    "        else:\n",
    "            # If we can't find the word in glove, randomly initialize\n",
    "            emb[i] = normal(scale=0.6, size=(n_fact,))\n",
    "\n",
    "    # This is our \"rare word\" id - we want to randomly initialize\n",
    "    emb[-1] = normal(scale=0.6, size=(n_fact,))\n",
    "    emb/=3\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb = create_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, (25000, 500), 500)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size,trn_seq.shape,seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 267s - loss: 0.6315 - acc: 0.6118 - val_loss: 0.4521 - val_acc: 0.8096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efe05ef4c50>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size,50,input_length=seq_len,weights=[emb],dropout=0.2,trainable=True),\n",
    "    Dropout(0.2),\n",
    "    Convolution1D(nb_filter=64,filter_length=5,border_mode='same',activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(trn_seq,labels_train,batch_size=256,nb_epoch=1,validation_data=(tst_seq,labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 276s - loss: 0.3870 - acc: 0.8324 - val_loss: 0.2957 - val_acc: 0.8846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efe1ce136d0>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "model.fit(trn_seq,labels_train,batch_size=256,nb_epoch=1,validation_data=(tst_seq,labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multisize CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_in = Input((vocab_size,50))\n",
    "conv = []\n",
    "for fsz in range(3,6):\n",
    "    x = Convolution1D(64,fsz,border_mode='same',activation='relu')(graph_in)\n",
    "    x = MaxPooling1D()(x)\n",
    "    x = Flatten()(x)\n",
    "    conv.append(x)\n",
    "out = Merge(mode='concat')(conv)\n",
    "graph = Model(graph_in,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size,50,input_length=seq_len,weights=[emb],trainable=False,dropout=0.2),\n",
    "    Dropout(0.25),\n",
    "    graph,\n",
    "    Dropout(0.25),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer=Adam(),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(trn_seq,labels_train,batch_size=64,nb_epoch=2,validation_data=(tst_seq,labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 500, 50)       250000      embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 500, 50)       0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  multiple              38592       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 48000)         0           model_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           4800100     dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 100)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             101         dropout_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 5,088,793\n",
      "Trainable params: 4,838,793\n",
      "Non-trainable params: 250,000\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 500), (None, 500, 50))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].input_shape,model.layers[0].output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_emb = Sequential([Embedding(vocab_size,50,input_length=seq_len,weights=[emb],trainable=False,dropout=0.2)])\n",
    "model_emb.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model_emb.predict([trn_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(362, 4999),\n",
       " (377, 4999),\n",
       " (383, 4999),\n",
       " (389, 4999),\n",
       " (390, 4999),\n",
       " (396, 4999),\n",
       " (397, 4999),\n",
       " (406, 4999),\n",
       " (408, 4999),\n",
       " (411, 4999),\n",
       " (413, 4999),\n",
       " (422, 4999),\n",
       " (423, 4999),\n",
       " (425, 4999),\n",
       " (435, 4999),\n",
       " (459, 4999),\n",
       " (469, 4999),\n",
       " (473, 4999),\n",
       " (477, 4999),\n",
       " (489, 4999)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i,j) for i,j in enumerate(trn_seq[0]) if j == 4999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0136,  0.0799,  0.0925, -0.0132, -0.1295, -0.1524,  0.1392, -0.1156, -0.0637,  0.0113,\n",
       "        0.1399, -0.1223, -0.0872, -0.3554, -0.0997,  0.2511,  0.1578,  0.1791,  0.3088,  0.0937,\n",
       "        0.1387,  0.091 ,  0.0358,  0.1773,  0.1835, -0.1727,  0.3204,  0.0736,  0.0088,  0.0529,\n",
       "        0.1503, -0.171 ,  0.0563,  0.1807, -0.1339, -0.0013, -0.04  ,  0.0066,  0.1301,  0.1117,\n",
       "       -0.3067, -0.4248, -0.18  , -0.1642, -0.129 , -0.1151, -0.0323, -0.0582, -0.0533, -0.2204], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0][362]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
