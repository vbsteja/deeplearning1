{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "welcome to the first week of deeplearning course, in this week we are going to achive a state of the art results using the CNN(Convolutional Neural Networks) to make the computers see the images thanks to deeplearning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to this week's Task: Dogs vs Cats "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are going to create a modle [Dogs vs Cats](https://www.kaggle.com/c/dogs-vs-cats) to enter the kaggle competition.there are a total of 25000 images labelled dogs and cats for training and 12500  in the test set that we have to lable for this competition. According to the kaggle website (end of 2013): *\"**State of the Art**:The current literature suggests machine classifiers can score above 80% accuracy on this task\"*, so if we can beat the 80% then we will be at the utting edge as of 2013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There isn't much to configure ,just a few small configuration steps.\n",
    "\n",
    "this is for showing plots in the webpage itself - we always wanted this when working in jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path to data, here i am placing the data in the temp directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"data/dogscats/dogscats/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few basic libraries we will need for the initial exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division,print_function\n",
    "\n",
    "import os,json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(precision = 4,linewidth = 100)\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have created a most imaginatively utils.py, import that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: GeForce 940MX (0000:03:00.0)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import utils; reload(utils)\n",
    "from utils import plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a pretrained model with our Vgg16 class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our first step is to simply use a model that has been fully created for us, which can recognizes a wide variety of (1000) images. we will use VGG Model which won the 2014 imagenet competition, it is very simple to create and understand. the VGG Imagenet team created a both larger,slower and slightly more accurate model(VGG19) and smaller,faster(VGG16). we will be using VGG16, since the slower performance of VGG19 is not note worthy os slight performance accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The punchline: state of the art custom model in 7 lines of code\n",
    "\n",
    "Here's everything you need to do to get >97% accuracy on the Dogs vs Cats dataset - we won't analyze how it works behind the scenes yet, since at this stage we're just going to focus on the minimum necessary to actually do useful work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11099 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/1\n",
      "11099/11099 [==============================] - 898s - loss: 0.1337 - acc: 0.9669 - val_loss: 0.0574 - val_acc: 0.9820\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "import vgg16\n",
    "from vgg16 import Vgg16\n",
    "\n",
    "vgg = Vgg16()\n",
    "batches = vgg.get_batches(path+'train',batch_size = batch_size)\n",
    "batches_valid = vgg.get_batches(path+'valid',batch_size = batch_size * 2)\n",
    "vgg.finetune(batches)\n",
    "vgg.fit(batches,batches_valid,nb_epoch = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.  28.]\n",
      " [ 49.  64.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7f91887a7160>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "CUDARuntimeError",
     "evalue": "cudaErrorUnknown: unknown error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCUDARuntimeError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6a6048277b3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mx_on_gpu1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mcupy/cuda/device.pyx\u001b[0m in \u001b[0;36mcupy.cuda.device.Device.__enter__ (cupy/cuda/device.cpp:1951)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/cuda/runtime.pyx\u001b[0m in \u001b[0;36mcupy.cuda.runtime.getDevice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/cuda/runtime.pyx\u001b[0m in \u001b[0;36mcupy.cuda.runtime.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCUDARuntimeError\u001b[0m: cudaErrorUnknown: unknown error"
     ]
    }
   ],
   "source": [
    "import cupy\n",
    "with cupy.cuda.Device(1):\n",
    "    x_on_gpu1 = cupy.array([1, 2, 3, 4, 5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
